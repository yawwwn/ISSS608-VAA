[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "pacman::p_load(ggstatsplot,tidyverse)\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n#set.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"all\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-models",
    "title": "Hands-on_Ex04",
    "section": "Visualising models",
    "text": "Visualising models\n\npacman::p_load(readxl, performance, parameters, see)\n\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\",\"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Installing packages\n\npacman::p_load(ggiraph, plotly,\n              patchwork, DT, tidyverse)\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)\n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(tooltip = CLASS,\n        data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )    \n)\n\n\n\n\n\n\nDT::datatable(exam_data, class= \"compact\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03_2.html",
    "title": "Hands-on_Ex03_2",
    "section": "",
    "text": "pacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\nglobalPop\n\n# A tibble: 6,204 × 6\n   Country      Year Young   Old Population Continent\n   &lt;fct&gt;       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;fct&gt;    \n 1 Afghanistan  1996  83.6   4.5     21560. Asia     \n 2 Afghanistan  1998  84.1   4.5     22913. Asia     \n 3 Afghanistan  2000  84.6   4.5     23898. Asia     \n 4 Afghanistan  2002  85.1   4.5     25268. Asia     \n 5 Afghanistan  2004  84.5   4.5     28514. Asia     \n 6 Afghanistan  2006  84.3   4.6     31057  Asia     \n 7 Afghanistan  2008  84.1   4.6     32738. Asia     \n 8 Afghanistan  2010  83.7   4.6     34505. Asia     \n 9 Afghanistan  2012  82.9   4.6     36416. Asia     \n10 Afghanistan  2014  82.1   4.7     38327. Asia     \n# ℹ 6,194 more rows\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +\n  ease_aes('linear')\n\n\n\n\n\ngg &lt;-ggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year), \n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young')\n\nWarning in geom_point(aes(size = Population, frame = Year), alpha = 0.7, :\nIgnoring unknown aesthetics: frame\n\nggplotly(gg)\n\nWarning in p$x$data[firstFrame] &lt;- p$x$frames[[1]]$data: number of items to\nreplace is not a multiple of replacement length"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Check packages\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\nLoad Data\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nggplot(data=exam_data, aes(x = MATHS, y = ENGLISH)) + \n  geom_point() +\n   geom_smooth(method=lm, \n              linewidth=0.5) +\n    geom_label_repel(aes(label = ID)) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n    ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: ggrepel: 317 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_wsj() +\n  theme(plot.title = element_text(size = 25))\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n(p1 / p2 | p3) +\nplot_annotation(tag_levels = 'I')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-On_Ex05/Hands--on_Ex05.html",
    "href": "Hands-on_Ex/Hands-On_Ex05/Hands--on_Ex05.html",
    "title": "Hands-On_Ex05",
    "section": "",
    "text": "pacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\n\nRows: 54 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): label, Department, Title\ndbl (1): id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\nRows: 9063 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): SentDate, Subject, MainSubject, sourceLabel, targetLabel\ndbl  (2): source, target\ntime (1): SentTime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'source', 'target'. You can override using\nthe `.groups` argument.\n\n\n\nGAStech_edges_aggregated\n\n# A tibble: 1,372 × 4\n   source target Weekday   Weight\n    &lt;dbl&gt;  &lt;dbl&gt; &lt;ord&gt;      &lt;int&gt;\n 1      1      2 Sunday         5\n 2      1      2 Monday         2\n 3      1      2 Tuesday        3\n 4      1      2 Wednesday      4\n 5      1      2 Friday         6\n 6      1      3 Sunday         5\n 7      1      3 Monday         2\n 8      1      3 Tuesday        3\n 9      1      3 Wednesday      4\n10      1      3 Friday         6\n# ℹ 1,362 more rows\n\n\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…\n\n\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# ℹ 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\nggraph(GAStech_graph) + #used to initialize the network plot\n  geom_edge_link() +  #to visualize the edges as lines\n  geom_node_point() + #represent the nodes as points\n  theme_void() #remove any background elements from the plot and create a clean, minimalistic appearance.\n\nUsing \"stress\" as default layout\n\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\nUsing \"stress\" as default layout\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'from'. You can override using the\n`.groups` argument.\n\n\n\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computed. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launch-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launch-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computed. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#horizontal-bar-chart-with-theme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#horizontal-bar-chart-with-theme",
    "title": "Hands-on Exercise 1",
    "section": "Horizontal Bar Chart with theme",
    "text": "Horizontal Bar Chart with theme\n\nggplot(data = exam_data, aes( x = RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal() +\n  theme(\n    panel.background = element_rect(fill = \"lightblue\", color = \"lightblue\",\n                                    linewidth = 0.5, linetype = \"solid\"),\n    panel.grid.major = element_line(linewidth = 0.5, linetype = 'solid', colour = \"white\"), \n    panel.grid.minor = element_line(linewidth = 0.25, linetype = 'solid', colour = \"white\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#in-class-exercise-makeover-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#in-class-exercise-makeover-1",
    "title": "Hands-on Exercise 1",
    "section": "In-Class Exercise (Makeover #1)",
    "text": "In-Class Exercise (Makeover #1)\n\nggplot(data = exam_data, aes(x=reorder(RACE,RACE,\n                     function(x)-length(x)))) +\n  geom_bar() +\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(after_stat(count), \", \", \n      round(after_stat(count)/sum(after_stat(count))*100, 1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\npupils\")+\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#in-class-exercise-fct_infre",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#in-class-exercise-fct_infre",
    "title": "Hands-on Exercise 1",
    "section": "In-Class Exercise fct_infre()",
    "text": "In-Class Exercise fct_infre()\n\nexam_data %&gt;%\n  mutate(RACE = fct_infreq(RACE)) %&gt;%\n  ggplot(aes(x = RACE)) + \n  geom_bar()+\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(after_stat(count), \", \", \n      round(after_stat(count)/sum(after_stat(count))*100,\n            1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "City of Engagement, with a total population of 50,000, is a small city located at Country of Nowhere. The city serves as a service centre of an agriculture region surrounding the city. The main agriculture of the region is fruit farms and vineyards. The local council of the city is in the process of preparing the Local Plan 2023.\nA sample survey of 1000 representative residents had been conducted to collect data related to their household demographic and spending patterns, among other things. The city aims to use the data to assist with their major community revitalization efforts, including how to allocate a very large city renewal grant they have recently received.\nThe task is to reveal the demographic and financial characteristics of the city of Engagement by using appropriate static and interactive statistical graphics methods, using ggplot2, its extensions, as well as tidyverse family of packages."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#install-r-packages",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#install-r-packages",
    "title": "Take Home Exercise 1",
    "section": "3.1 Install R Packages",
    "text": "3.1 Install R Packages\nThe R packages are installed using pacman::p_load(). Below is a list of main packages installed:\n\ntidyverse: Comprehensive collection of data manipulation and visualization packages.\nplotly: Interactive data visualization package for creating dynamic charts.\nggstatsplot: Enhances ggplot2 with statistical visualization capabilities.\ngganimate: Creates animated plots using ggplot2.\nggrepel: Avoids label overlap in ggplot2 plots.\nggridges: Creates ridgeline plots in ggplot2.\nggiraph: Adds interactivity to ggplot2 plots.\nwaffles: Creates waffle charts for visualizing proportions or percentages.\npatchwork: Combines multiple ggplot2 plots into a single layout.\n\n\npacman::p_load(tidyverse, ggthemes, plotly, lubridate, ggpubr, ggrepel, gganimate, knitr, ggridges, ggdist, reshape2, ggstatsplot, ggiraph, patchwork, waffle,ggiraphExtra)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#loading-data",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#loading-data",
    "title": "Take Home Exercise 1",
    "section": "3.2 Loading data",
    "text": "3.2 Loading data\nImporting both datasets and assigning it to a variable each.\n\nparticipants &lt;- read_csv(\"data/Participants.csv\")\nfin_journal &lt;- read_csv(\"data/FinancialJournal.csv\")\n\n\n3.2.1 Participants Data\nBelow show a snippet of the data\n\nparticipants\n\n# A tibble: 1,011 × 7\n   participantId householdSize haveKids   age educationLevel      interestGroup\n           &lt;dbl&gt;         &lt;dbl&gt; &lt;lgl&gt;    &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;        \n 1             0             3 TRUE        36 HighSchoolOrCollege H            \n 2             1             3 TRUE        25 HighSchoolOrCollege B            \n 3             2             3 TRUE        35 HighSchoolOrCollege A            \n 4             3             3 TRUE        21 HighSchoolOrCollege I            \n 5             4             3 TRUE        43 Bachelors           H            \n 6             5             3 TRUE        32 HighSchoolOrCollege D            \n 7             6             3 TRUE        26 HighSchoolOrCollege I            \n 8             7             3 TRUE        27 Bachelors           A            \n 9             8             3 TRUE        20 Bachelors           G            \n10             9             3 TRUE        35 Bachelors           D            \n# ℹ 1,001 more rows\n# ℹ 1 more variable: joviality &lt;dbl&gt;\n\n\n\n\n3.2.2 FinancialJournal Data\n\nfin_journal\n\n# A tibble: 1,513,636 × 4\n   participantId timestamp           category  amount\n           &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;      &lt;dbl&gt;\n 1             0 2022-03-01 00:00:00 Wage      2473. \n 2             0 2022-03-01 00:00:00 Shelter   -555. \n 3             0 2022-03-01 00:00:00 Education  -38.0\n 4             1 2022-03-01 00:00:00 Wage      2047. \n 5             1 2022-03-01 00:00:00 Shelter   -555. \n 6             1 2022-03-01 00:00:00 Education  -38.0\n 7             2 2022-03-01 00:00:00 Wage      2437. \n 8             2 2022-03-01 00:00:00 Shelter   -557. \n 9             2 2022-03-01 00:00:00 Education  -12.8\n10             3 2022-03-01 00:00:00 Wage      2367. \n# ℹ 1,513,626 more rows"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-wrangling",
    "title": "Take Home Exercise 1",
    "section": "3.3 Data Wrangling",
    "text": "3.3 Data Wrangling\nThe raw data from both data sets requires additional wrangling and manipulation before they can be processed and analysed further.\n\n3.3.1 Participants Data\nis.na() function is used to check if any values are missing from the participants data set. No values are missing.\n\nany(is.na(participants))\n\n[1] FALSE\n\n\nTo ensure subsequent statistical and categorical data analysis would not encounter problems, it is also best practice to convert variables, especially categorical ones, into factor type.\n\neducationLevel and interestGroup are in chr type and is converted to fctr .\nhaveKids is in lgl boolean type. However, we will also convert to fctr.\nhouseholdSize is in dbl type. While it is technically accurate, it is not useful for analysis. Hence we will convert to fctr type.\nparticipantId will be converted to chr type.\n\n\n\nShow the code\n# Convert variables to factor type\ncol &lt;- c(\"haveKids\",\"educationLevel\",\"interestGroup\", \"householdSize\")\nparticipants &lt;- participants %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(participantId = as.character(participantId))\n\n# Define the custom order of education levels\ncustom_order &lt;- c(\"Low\", \"HighSchoolOrCollege\", \"Bachelors\", \"Graduate\")\n\n# Convert educationLevel to a factor with custom order\nparticipants$educationLevel &lt;- factor(participants$educationLevel, levels = custom_order)\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo ensure better visual representation, we can explicitly specify the order of education level. This can only be done for fctr data type!\n\n\n\n\n3.3.2 FinancialJournal Data\nSimilarly, for FinancialJournal dataset, a is.na() function is performed to check for missing values.\n\nany(is.na(fin_journal))\n\n[1] FALSE\n\n\n\n3.3.2.1 Remove duplicates\nNext, given that it is a large data set, we shall do a duplicate check using duplicated. There are a total of 1,113 duplicated data.\n\nduplicates &lt;- duplicated(fin_journal)\nsum(duplicates)\n\n[1] 1113\n\n\n\n\n\n\n\n\nCaution\n\n\n\nWhile duplicate checks are important to preserve data integrity, it is important to be careful as not every seemingly duplicated data are duplicates, especially in the absence of a unique id. In the above example, it is also possible for 2 records to be the same but yet distinct in business nature.\n\n\nAs timestamp is the only remotely unique data, we use unique to observe whether duplicated data are sparse across the dates.\n\ndistinct_months &lt;- unique(fin_journal[duplicates, \"timestamp\"])\ndistinct_months\n\n# A tibble: 1 × 1\n  timestamp          \n  &lt;dttm&gt;             \n1 2022-03-01 00:00:00\n\n\nSince all of the duplicated data belongs to the same month, there’s reason to believe they are genuine duplicates.\n\n\n3.3.2.2 Change data type\nAs such, we shall create a new clean data set and name it fin_journal_clean. We would also perform some data wrangling by changing the data types of the variables:\n\nConvert timestamp from POSIXct to date format, keeping only month and year.\n\n\nfin_journal_clean &lt;- distinct(fin_journal) %&gt;%\n  mutate(timestamp = floor_date(timestamp, \"month\")) %&gt;%\n  mutate(timestamp = as.Date(timestamp)) %&gt;%\n  mutate(participantId = as.character(participantId))\n\n\n\n3.3.2.3 Pivot table\nAs the fin_journal_clean table is a long vertical table, we will perform a pivot to a horizontal table where each of the expense categories have its own column.\n\n\nShow the code\n#pivot to horizontal table\nfin_journal_pivot &lt;- fin_journal_clean %&gt;%\n  group_by(participantId, timestamp, category) %&gt;%\n  summarize(total_amount = sum(amount)) %&gt;%\n  pivot_wider(\n    id_cols = c(participantId, timestamp),\n    names_from = category,\n    values_from = total_amount\n  ) %&gt;%\n  #for columns that are numeric, replace NA values with 0\n  mutate(across(where(is.numeric), ~if_else(is.na(.), 0, .)))\n\n\nBelow is a preview of the pivoted table.\n\nfin_journal_pivot\n\n# A tibble: 10,691 × 8\n# Groups:   participantId, timestamp [10,691]\n   participantId timestamp  Education  Food Recreation Shelter   Wage\n   &lt;chr&gt;         &lt;date&gt;         &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 0             2022-03-01     -38.0 -268.     -349.    -555. 11932.\n 2 0             2022-04-01     -38.0 -266.     -219.    -555.  8637.\n 3 0             2022-05-01     -38.0 -265.     -383.    -555.  9048.\n 4 0             2022-06-01     -38.0 -257.     -466.    -555.  9048.\n 5 0             2022-07-01     -38.0 -270.    -1070.    -555.  8637.\n 6 0             2022-08-01     -38.0 -262.     -314.    -555.  9459.\n 7 0             2022-09-01     -38.0 -256.     -295.    -555.  9048.\n 8 0             2022-10-01     -38.0 -267.      -25.0   -555.  8637.\n 9 0             2022-11-01     -38.0 -261.     -377.    -555.  9048.\n10 0             2022-12-01     -38.0 -266.     -357.    -555.  9048.\n# ℹ 10,681 more rows\n# ℹ 1 more variable: RentAdjustment &lt;dbl&gt;\n\n\n\n\n3.3.2.4 Missing participants\nBelow, we do a check to ensure that all participants have provided the necessary data. That is, a reasonableness check that for every participant, there should be the same number of months (12) of data.\n\n\nShow the code\n# Calculate the expected number of months based on the total number of unique months in the dataset\nexpected_months &lt;- n_distinct(fin_journal_pivot$timestamp)\nexpected_months\n\n\n[1] 12\n\n\nWe identify and count the number of participants that have less than 12 months of data.\n\n\nShow the code\n# Group the data by participantId and calculate the actual number of months for each participant\nparticipant_months &lt;- fin_journal_pivot %&gt;%\n  group_by(participantId) %&gt;%\n  summarize(actual_months = n_distinct(timestamp))\n\n# Identify participants with missing data\nmissing_participants &lt;- participant_months %&gt;%\n  filter(actual_months &lt; expected_months)\n\n\nThere are total of 113 participants with data missing in some months. It is believed/assumed that they have dropped out of the data collection.\n\ncount(missing_participants)\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1   131\n\n\nHence, we shall remove this participants and their data.\n\n\nShow the code\nfin_journal_pivot_final &lt;- fin_journal_pivot %&gt;%\n  anti_join(missing_participants, by = \"participantId\")\n\n\n\n\n3.3.2.5 Final Wrangling\nFinally, we shall perform some final clean-ups. These include:\n\nRemove timestamp column and summarise/group the remaining data. As data are collected upon 12 month period, the time-series data might not be as useful to us. Data can be interpreted on a monthly or annual basis.\nAdding expense categories together to form a new variable called total_expenses\nAdding income categories together to form a new variable called total_income\nCreating a new variable called expense_ratio, which takes total_expenses / total_income\n\n\n\nShow the code\nfin_journal_pivot_final &lt;- fin_journal_pivot_final %&gt;%\n  # removing timestamp column\n  select(-matches(\"timestamp\")) %&gt;%\n  group_by(participantId) %&gt;%\n  summarize_at(vars(Education:RentAdjustment),sum) %&gt;%\n  ##Sum total expenses and convert to absolute value\n  mutate(total_expenses = abs(Education + Food + Recreation + Shelter)) %&gt;%\n  mutate(total_income = RentAdjustment + Wage) %&gt;%\n  mutate(Expense_ratio = total_expenses/total_income)\n\n\n\n\n3.3.2.6 Joining data sets\nFinally, we combine both data sets to form a unified one combined_pivot_data.\n\n\nShow the code\ncombined_pivot_data &lt;- left_join(fin_journal_pivot_final, participants, by = \"participantId\")\n\n\nBelow is a sample of the data:\n\nkable(head(combined_pivot_data), \"simple\")\n\n\n\n\nparticipantId\nEducation\nFood\nRecreation\nShelter\nWage\nRentAdjustment\ntotal_expenses\ntotal_income\nExpense_ratio\nhouseholdSize\nhaveKids\nage\neducationLevel\ninterestGroup\njoviality\n\n\n\n\n0\n-456.0646\n-3141.976\n-4384.0672\n-6659.863\n109816.59\n0\n14641.971\n109816.59\n0.1333311\n3\nTRUE\n36\nHighSchoolOrCollege\nH\n0.0016267\n\n\n1\n-456.0646\n-3167.336\n-6637.5107\n-6659.863\n96374.93\n0\n16920.775\n96374.93\n0.1755724\n3\nTRUE\n25\nHighSchoolOrCollege\nB\n0.3280865\n\n\n10\n-153.7493\n-4741.141\n-3088.0366\n-6730.812\n79303.82\n0\n14713.739\n79303.82\n0.1855363\n3\nTRUE\n48\nHighSchoolOrCollege\nD\n0.5571760\n\n\n100\n0.0000\n-3695.506\n-4425.2218\n-7168.445\n46918.02\n0\n15289.173\n46918.02\n0.3258700\n2\nFALSE\n29\nLow\nF\n0.1426862\n\n\n1000\n0.0000\n-5987.265\n-6466.7517\n-6199.918\n29292.89\n0\n18653.935\n29292.89\n0.6368076\n1\nFALSE\n56\nGraduate\nB\n0.9830125\n\n\n1001\n0.0000\n-3197.202\n-211.6989\n-5464.707\n46233.82\n0\n8873.607\n46233.82\n0.1919289\n1\nFALSE\n49\nGraduate\nC\n0.0434335"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#summary-of-data",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#summary-of-data",
    "title": "Take Home Exercise 1",
    "section": "3.3 Summary of Data",
    "text": "3.3 Summary of Data\nThere are a total of 1,011 participants interviewed. Below list the summary statistics for each of the variables.\n\n\nShow the code\n#quantitative columns to describe\nsel_col &lt;- c(\"householdSize\", \"age\", \"joviality\")\n#filter dataset\nsel_data &lt;- combined_pivot_data %&gt;%\n  select(all_of(sel_col))\npsych::describe(sel_data)\n\n\n               vars   n  mean    sd median trimmed   mad min max range  skew\nhouseholdSize*    1 880  1.90  0.81   2.00    1.87  1.48   1   3     2  0.19\nage               2 880 39.13 12.40  39.00   39.19 16.31  18  60    42 -0.03\njoviality         3 880  0.47  0.29   0.44    0.46  0.35   0   1     1  0.22\n               kurtosis   se\nhouseholdSize*    -1.45 0.03\nage               -1.21 0.42\njoviality         -1.14 0.01"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#demographics",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#demographics",
    "title": "Take Home Exercise 1",
    "section": "4.1 Demographics",
    "text": "4.1 Demographics\nBelow is a high-level overview of the demographics of participants.\n\nAgeHousehold SizeFinancial BehaviorEducation LevelHave KidsOverall Income & Expenses\n\n\nObservation:\nThe age of the participants are relatively evenly distributed across the age ranges, with lowest being 18 and oldest being 60.\n\n\nShow the code\nplot &lt;- ggplot(combined_pivot_data, \n       aes(x = age)) +\n  geom_histogram(binwidth = 5, \n                 fill = \"lightblue\", \n                 color = \"black\") +\n  labs(x = \"Age\", y = \"No. of Participants\") +\n  ggtitle(\"Distribution of Age\") +\n  theme_minimal() +\n  theme(panel.grid.major.x = element_blank(), #remove vertical gridlines\n        panel.grid.minor.x = element_blank(),\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 14)) \n\nprint(plot)\n\n\n\n\n\nShow the code\nprint(as.data.frame(psych::describe(combined_pivot_data$age)))\n\n\n   vars   n     mean       sd median  trimmed     mad min max range      skew\nX1    1 880 39.13068 12.39922     39 39.18608 16.3086  18  60    42 -0.026236\n    kurtosis        se\nX1 -1.214038 0.4179775\n\n\n\n\nObservation:\n10% more participants live alone than have kids (household size more than 1)\n\n\nShow the code\n# Calculate the count and percentage\nparticipants_count &lt;- combined_pivot_data %&gt;%\n  group_by(householdSize) %&gt;%\n  summarize(\n    count = n()\n  ) %&gt;% \n  mutate(\n    householdSize = factor(householdSize),  # Convert to factor\n    householdSize_pct = round(count/sum(count)*100)\n  )\n\n# Choose a color palette\ncolor_palette &lt;- scales::brewer_pal(type = \"qual\")(length(unique(participants_count$householdSize)))\n\n# Create the pie chart using ggplot2\npie_chart &lt;- ggplot(participants_count, aes(x = \"\", y = householdSize_pct, fill = householdSize)) +\n  geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n  coord_polar(theta = \"y\") +\n  scale_fill_manual(values = color_palette, name = 'Household Size') +\n  geom_text(aes(label = paste0(householdSize_pct, \"%\")), position = position_stack(vjust = 0.5), color = \"white\") +\n  labs(title = \"Proportion of Household Sizes among participants\") +\n  theme_void() +\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5, size = 14))\n\n# Display the pie chart\npie_chart\n\n\n\n\n\n\n\nObservation:\nWe use waffle charts here to illustrate the breakdown of financials by the average participants. Out of total income, most are proportioned to Savings, followed by Shelter expenses, then Recreation, Food and lastly Education.\n\n\nShow the code\naverage_participant &lt;- combined_pivot_data %&gt;%\n  summarize(\n    FoodExpenses = abs(mean(Food)),\n    ShelterExpenses = abs(mean(Shelter)),\n    EducationExpenses = abs(mean(Education)),\n    RecreationExpenses = abs(mean(Recreation)),\n    Savings = mean(Wage + RentAdjustment - abs(`Food` + `Shelter`))\n  )\n\n# Calculate the proportions of expenses and savings\nexpenses &lt;- c(average_participant$FoodExpenses, average_participant$ShelterExpenses,average_participant$EducationExpenses, average_participant$RecreationExpenses )\nsavings &lt;- average_participant$Savings\ntotal &lt;- sum(expenses, savings)\nexpenses_prop &lt;- expenses / total\nsavings_prop &lt;- savings / total\n\n# Create a data frame for waffle chart\nwaffle_data &lt;- data.frame(\n  category = c(\"Food Expenses\", \"Shelter Expenses\", \"Education\", \"Recreation\", \"Savings\"),\n  total = c(expenses,savings),\n  proportion = c(expenses_prop, savings_prop)\n)\n\n# does not work for waffle charts unfortunately\nlegend_labels &lt;- c(\"Food Expenses\", \"Shelter Expenses\", \"Education\", \"Recreation\", \"Savings\")\n\nwaffle_chart &lt;- waffle(waffle_data$proportion*100, rows = 10, size = 1,\n                       colors = c(\"#F8766D\", \"#7CAE00\", \"#00BFC4\", \"#C77CFF\", \"#FFB621\"),\n                       title = list(label = \"Financial Breakdown of\\n Average Participant\", size = 10, face = \"bold\", hjust = 0.5),\n                       pad = 0.3\n)\nwaffle_chart\n\n\n\n\n\n\n\nObservation:\n47.95% of the participants have High School or College degrees whereas 6.56% of participants have low education level.\n\n\n\n\n\n\nTip\n\n\n\nHover over to see the number of participants and percentage breakdown!\n\n\n\n\nShow the code\n# Calculate the count for each education level\neducation_count &lt;- combined_pivot_data %&gt;%\n  group_by(educationLevel) %&gt;%\n  summarize(count = n())\n\n# Order the education levels by count\neducation_count &lt;- education_count[order(education_count$count, decreasing = TRUE), ]\n\n# Calculate percentage\neducation_count &lt;- education_count %&gt;%\n  mutate(percentage = count / sum(count) * 100)\n\n# Create the stacked bar chart using ggplot2\nstacked_bar_chart &lt;- ggplot(education_count, aes(x = \"\", y = count, fill = educationLevel, tooltip = paste(\"No. of Participants:\", count,\"&lt;br&gt;Percentage:\", round(percentage, 2), \"%\"))) +\n  geom_bar_interactive(stat = \"identity\", width = 1, color = \"white\") +\n  coord_flip() +\n  scale_fill_viridis_d(name = 'Household Size') +\n  labs(title = \"Education Level Breakdown\",\n       x = NULL, y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        plot.title = element_text(face = \"bold\", hjust = 0.5, size = 14))\n\n# Display the stacked bar chart\ngirafe(ggobj = stacked_bar_chart,\n       width_svg = 6,\n  height_svg = 6*0.618)\n\n\n\n\n\n\n\n\nObservation:\nMost of the participants do not have kids.\n\n\nShow the code\nggplot(data = combined_pivot_data, aes(x = haveKids)) +\n  geom_bar(fill = \"#00BFC4\", color = \"black\", width = 0.6) +\n  labs(x = \"Have Kids\", y = \"Count\", title = \"Distribution of Participants by whether they have kids\") +\n  theme_minimal() +\n  theme(\n    axis.text = element_text(face = \"bold\", hjust = 0.5, size = 14),\n    axis.title = element_text(size = 14, face = \"bold\"),\n    plot.title = element_text(size = 16, face = \"bold\"),\n    panel.grid.major.y = element_blank()\n  )\n\n\n\n\n\n\n\nObservation:\nAnnual Income is left-skewed - which indicates more of the participants have lower income whereas Annual Expenses seem to follow normal distribution.\n\n\nShow the code\np1 &lt;- ggplot(data=combined_pivot_data, \n             aes(x = total_income)) +\n  geom_histogram(bins = 20, \n                 #boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  labs(\n    x = \"Total Income\",\n    y = \"Count\",\n    title = \"Distribution of Annual Income\",\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank()\n  )\n\np2 &lt;- ggplot(data=combined_pivot_data, \n             aes(x = total_expenses)) +\n  geom_histogram(bins = 20, \n                 #boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  labs(\n    x = \"Total Expenses\",\n    y = \"Count\",\n    title = \"Distribution of Annual Expenses\",\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank()\n  )\n\np3 &lt;- ggplot(data=combined_pivot_data, \n             aes(x = Expense_ratio)) +\n  geom_histogram(bins = 20, \n                 #boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  labs(\n    x = \"Expenses Ratio\",\n    y = \"Count\",\n    title = \"Distribution of Expense Ratio\",\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank()\n  )\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#exploratory-data-visualisation",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#exploratory-data-visualisation",
    "title": "Take Home Exercise 1",
    "section": "4.2 Exploratory Data Visualisation",
    "text": "4.2 Exploratory Data Visualisation\n\n4.2.1 Ridgeline Plot\nA ridgeline plot is a visualization that displays the distribution of a numeric variable across groups as stacked smoothed curves, helping compare distribution shapes and densities. It provides a compact and visually appealing way to analyze and compare distributions, making it useful for exploring data with multiple categories or groups.\nFrom below, we can observe that:\n\nParticipants with higher education level makes higher wages, and that is consistent across all age groups\nHowever, there is no significant changes in wages at every education level.\nParticipants that live alone (household size = 1) has lower expenses that those with more than 1. However, there is no significant differences between participants with a spouse (household size = 2) and those with kids (household size = 3). In fact, both have the same distribution.\n\n\nEducation Level vs WageHousehold Size vs Expenses\n\n\n\n\nShow the code\ncombined_pivot_data &lt;- combined_pivot_data %&gt;%\n  mutate(AgeGroup = cut(age, breaks = c(0,20, 30, 40, 50, 60), labels = c(\"&lt;20\", \"20-30\", \"30-40\", \"40-50\", \"50-60\")))\n\nggplot(combined_pivot_data, \n       aes(y = educationLevel, \n           x = Wage, \n           fill = after_stat(x))) +\n  geom_density_ridges_gradient(scale = 3, \n                      alpha = 0.8\n                      ) +\n  scale_fill_viridis_c(name = \"Wage\",\n                       option = \"turbo\") +\n  labs(x = \"Wage\", \n       y = \"Education Level\", \n       title = \"Distribution of Wage by Education Level at Age Group {closest_state}\") +\n  \n  theme(legend.position=\"none\",\n  plot.title = element_text(face = \"bold\", size = 12),\n  axis.title.x = element_text(size = 10, hjust = 1),\n  axis.title.y = element_text(size = 10),\n  axis.text = element_text(size = 8)) +\n  \n  transition_states(combined_pivot_data$AgeGroup, transition_length = 0, state_length = 1)+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(combined_pivot_data, \n       aes(y = householdSize,\n           x = total_expenses, \n           fill = after_stat(x))) +\n  geom_density_ridges_gradient(scale = 3, \n                      alpha = 0.8\n                      ) +\n  scale_fill_viridis_c(name = \"Expenses\",\n                       option = \"turbo\") +\n  labs(x = \"Expenses\", \n       y = \"Household Size\", \n       title = \"Distribution of Expenses by Household Size at Age Group {closest_state}\") +\n  \n  theme(legend.position=\"none\",\n  text = element_text(family = \"Garamond\"),\n  plot.title = element_text(face = \"bold\", size = 12),\n  axis.title.x = element_text(size = 10, hjust = 1),\n  axis.title.y = element_text(size = 10),\n  axis.text = element_text(size = 8)) +\n  \n  transition_states(combined_pivot_data$AgeGroup, transition_length = 0, state_length = 1)+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n4.2.2 Interactive Scatter Plot\nScatter plots display the relationship between two continuous variables as a collection of individual data points on a two-dimensional plane. The below visualisation focus on Joviality score as the y-axis variable, to observe the relationship with other variables. It allows the City Planners to select the x-axis of the variables they wish to study.\nFor x-axis, we selected Annual Income, Annual Expense, Recreation Expenses, Expense Ratio, and Age. This is to discover patterns of user’s financial behavior versus their happiness level. Recreation Expenses is the only expense category chosen as it is assumed that it is the only one which doesn’t cover the basic needs (according to Maslow’s Hierarchy of Needs!).\nAs the below scatterplot is only plotted for visualisation and not for statistical inquiries (which we would do below at a later section!), plot_ly is used to prepare the interactive plot.\nIn order to prepare a dynamic chart for users to interact and change the variables, updatemenus argument is parsed.\nUsers can also hover over the plots to see the tooltip.\n\n\nShow the code\n#Base plot\nplot_ly(data = combined_pivot_data,\n        x = ~total_income,\n        y = ~joviality,\n        hovertemplate = ~paste(\"&lt;br&gt;Age:\", age,\n                               \"&lt;br&gt;Total Income\", total_income,\n                               \"&lt;br&gt;Total Expenses:\", total_expenses,\n                               \"&lt;br&gt;Expense Ratio:\", Expense_ratio),\n        type = 'scatter',\n        mode = 'markets',\n        marker = list(opacity = 0.7,\n                      color = '#00BFC4',\n                      line = list(width = 0.2, color = 'white'))) |&gt; \n\n  layout(title = list(text=\"&lt;b&gt;Interactive scatterplot of participants'\\nTotal Annual Income vs Joviality Score&lt;/b&gt;\", font = list(size = 14)),\n         xaxis = list(title = \"Total Annual Inncome\"),\n         yaxis = list(title = \"Joviality Score\"),\n         \n#creating dropwdown menus to allow selection of parameters on x-axis and y-axis \n         updatemenus = list(list(type = \"dropdown\",\n                                 direction = \"up\",\n                                 xref = \"paper\",\n                                 yref = \"paper\",\n                                 xanchor = \"left\",\n                                 yanchor = \"top\",\n                                 x = 1,\n                                 y = 0,\n                                 buttons = list(\n                                   list(method = \"update\",\n                                        args = list(list(x = list(combined_pivot_data$total_income)),\n                                                    list(xaxis = list(title = \"Total Annual Income\"))),\n                                        label = \"Annual Income\"),\n                                   list(method = \"update\",\n                                        args = list(list(x = list(combined_pivot_data$total_expenses)),\n                                                    list(xaxis = list(title = \"Total Annual Expenses\"))),\n                                        label = \"Annual Expenses\"),\n                                   list(method = \"update\",\n                                        args = list(list(x = list(abs(combined_pivot_data$Recreation))),\n                                                    list(xaxis = list(title = \"Recreation Expenses\"))),\n                                        label = \"Recreation Expenses\"),\n                                   list(method = \"update\",\n                                        args = list(list(x = list(combined_pivot_data$Expense_ratio)),\n                                                    list(xaxis = list(title = \"Expense Ratio\"))),\n                                        label = \"Expense Ratio\"),\n                                   list(method = \"update\",\n                                        args = list(list(x = list(combined_pivot_data$age)),\n                                                    list(xaxis = list(title = \"Age\"))),\n                                        label = \"Age\")   \n                                   )\n                                 )\n                            )\n         )\n\n\n\n\n\n\nFrom above, we can observe and draw following insights:\n\nAnnual Income has no positive correlation (in fact, somewhat negative!) with Joviality Score. In fact, participants that are drawing high income have lower joviality score.\nTotal Expenses, Recreation Expenses and Expense Ratio have positive correlation with Joviality Score.\nThere are no correlation between Age and Joviality Score.\n\n\n\n4.2.3 Interactive Violin plot\nA Violin plot, is a graphical representation of the distribution of a continuous variable through quartiles. It is generally used to discover relationship between continuous and discrete variables, and allow for the visualisation of kernel density.\nThe below visualisation also allow City Planners to select the x-axis and y-axis they intend to study.\nFor y-axis, Joviality, Total Annual Income and Expense Ratio are chosen. For x-axis, categorical and discrete variables are chosen. These include Age Group, Education Level, Household size, whether participants Have Kids?, Income Level, and Interest Group.\nIncome Level is a new variable that is added to the data set. It is derived by breaking down the Total Annual Income of participants into 4 different quantiles, and respectively named as {“Low”, “Medium”, “High”, “Very High”}.\nSimilar to the scatterplot, plot_ly is used to prepare the interactive plot.\n\n\nShow the code\n# Define the income levels based on quantiles\nincome_levels &lt;- quantile(combined_pivot_data$total_income, probs = c(0, 0.25, 0.5, 0.75, 1))\n\n# Add a new column with income levels\ncombined_pivot_data &lt;- combined_pivot_data %&gt;%\n  mutate(income_level = factor(cut(total_income, breaks = income_levels, include.lowest = TRUE, labels = c(\"Low\", \"Medium\", \"High\", \"Very High\"),ordered = TRUE)))\n\n#Base plot\nplot_ly(data = combined_pivot_data,\n        x = ~AgeGroup,\n        y = ~joviality,\n        line = list(width =1),\n        type = \"violin\",\n        marker = list(opacity = 0.5,\n          line = list(width = 2)),\n        box = list(visible = T),\n        meanline = list(visible = T,\n                        color = \"red\",\n                        width = 2)) |&gt; \n  \n  layout(title = list(text=\"&lt;b&gt;Distribution of Joviality by Age Group&lt;/b&gt;\", font = list(size = 14)),\n         xaxis = list(title = \"Total Annual Inncome\"),\n         yaxis = list(title = \"Joviality Score\"),\n         \n#creating dropwdown menus to allow selection of parameters on x-axis \n         updatemenus = list(list(type = 'dropdown',\n                                 direction = 'up',\n                                 xref = \"paper\",\n                                 yref = \"paper\",\n                                 xanchor = \"left\",\n                                 yanchor = \"top\",\n                                 x = 1,\n                                 y = 0,\n                                 buttons = \n                                   list(\n                                   list(method = \"update\",\n                                        args = list(list(x = list(combined_pivot_data$AgeGroup)),\n                                                    list(xaxis = list(title = \"Age Group\"))),\n                                        label = \"Age Group\"),\n                                   list(method = \"update\",\n                                        args = list(list(x = list(combined_pivot_data$educationLevel)),\n                                                    list(xaxis = list(title = \"Education Level\", categoryorder = \"mean ascending\"))),                                        label = \"Education Level\"),\n                                   list(method = \"update\",\n                                        args = list(list(x = list(combined_pivot_data$householdSize)),\n                                                    list(xaxis = list(title = \"Household Size\"))),\n                                        label = \"Household Size\"),\n                                   list(method = \"update\",\n                                        args = list(list(x = list(combined_pivot_data$haveKids)),\n                                                    list(xaxis = list(title = \"Have Kids\"))),\n                                        label = \"Have Kids?\"),\n                                   list(method = \"update\",\n                                        args = list(list(x = list(combined_pivot_data$income_level)),\n                                                    list(xaxis = list(title = \"Income Level\", categoryorder = \"mean descending\"))),\n                                        label = \"Income Level\"),\n                                   list(method = \"update\",\n                                        args = list(list(x = list(combined_pivot_data$interestGroup)),\n                                                    list(xaxis = list(title = \"Interest Group\", categoryorder = \"mean descending\"))),\n                                        label = \"Interest Group\")\n                                   \n                            \n                                 )\n                                 ),\n                            list(type = \"dropdown\",\n                                 xref = \"paper\",\n                                 yref = \"paper\",\n                                 xanchor = \"left\",\n                                 yanchor = \"top\",\n                                 x = 0,\n                                 y = 1.05,\n                                 buttons = list(\n                                   list(method = \"update\",\n                                        args = list(list(y = list(combined_pivot_data$joviality)),\n                                                    list(yaxis = list(title = \"Joviality\", categoryorder = \"category ascending\"))),\n                                        label = \"Joviality\"),\n                                   list(method = \"update\",\n                                        args = list(list(y = list(combined_pivot_data$Expense_ratio)),\n                                                    list(yaxis = list(title = \"Expense Ratio\"))),\n                                        label = \"Expense Ratio\"),\n                                   list(method = \"update\",\n                                        args = list(list(y = list(combined_pivot_data$total_income)),\n                                                    list(yaxis = list(title = \"Total Annual Income\"))),\n                                        label = \"Total Annual Income\")\n                                   )\n                                 )\n                            )\n         )\n\n\n\n\n\n\nFrom above, we can observe and draw following insights:\n\nFor Joviality Score, there is minimal difference between the means/medians when plotted against all other variables except Education Level. The violin plot reveals lower mean/median for Jovality Score for higher education levels compared to lower one.\nFor Expense Ratio, similarly, there is minimal difference between the means/medians of most variables. In this case, only Education Level and Income Level was observed to have largely different means/medians across the group. Participants with low Education Level have higher expense ratio mean/median that those with higher Education Level. The other observation is that among the participants, those with very high Income Level had much lower mean/median expense ratio, indicating a much higher saving ratio that those with low Income Level, which could indicate that those with high spending power are not spending as much as they are expected to.\nFor Total Annual Income, there’s no surprise that again, only when plotted against Education Level did we observe a difference in means/medians of the groups. Participants with higher Education Level earned more on a annual basis than those with low Education Level. Those with low education level has much lower variance, whereas those with high education level observed wider variances."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#visualising-uncertainty",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#visualising-uncertainty",
    "title": "Take Home Exercise 1",
    "section": "4.3 Visualising Uncertainty",
    "text": "4.3 Visualising Uncertainty\nVisualizing uncertainty in data is a challenging task in data visualization. Often, we interpret data points as precise representations of true values, neglecting the inherent uncertainty. Hence, it is important to note these uncertainties either in error bars or confidence bands.\nThe below visualisation uses stat_pointinterval() of ggdist package to build a visual of displaying distribution of different variables.\nBased on the insights and observation from the above exploratory data visualization, we selected the key variables such as Education Level, Total Income, Total Expense and Expense Ratio to visualise the uncertainties.\n\nEducation Level vs Total IncomeEducation Level vs Expense RatioIncome Level vs JovialityInterest Group vs Recreation Expenses\n\n\n\n\nShow the code\ncombined_pivot_data %&gt;%\n  ggplot(aes(x = educationLevel, \n             y = total_income)) +\n  \n  stat_pointinterval(\n    aes(interval_color = stat(level)),\n    .width = c(0.95, 0.99),\n    .point = mean,\n    .interval = qi,\n    point_color = \"darkred\",\n    show.legend = FALSE) +\n  \n  #Defining the color of the intervals \n  scale_color_manual(\n    values = c(\"blue2\", \"darkgreen\"),\n    aesthetics = \"interval_color\") +\n  \n  labs(\n    title = \"Visualising uncertainty in mean estimates of Total Annual income\\nby Education Level\",\n    subtitle = \"95% and 99% quantiles intervals at mean point\",\n    x = \"Education level\",\n    y = \"Annual Income\") +\n  \n   theme_minimal() +\n  \n  theme(plot.title = element_text(face = \"bold\", size = 12),\n        plot.subtitle = element_text(size = 10),\n        axis.text.x = element_text(hjust = 1))\n\n\n\n\n\n\n\n\n\nShow the code\ncombined_pivot_data %&gt;%\n  ggplot(aes(x = educationLevel, \n             y = Expense_ratio)) +\n  \n  stat_pointinterval(\n    aes(interval_color = stat(level)),\n    .width = c(0.95, 0.99),\n    .point = mean,\n    .interval = qi,\n    point_color = \"darkred\",\n    show.legend = FALSE) +\n  \n  #Defining the color of the intervals \n  scale_color_manual(\n    values = c(\"blue2\", \"darkgreen\"),\n    aesthetics = \"interval_color\") +\n  \n  labs(\n    title = \"Visualising uncertainty in mean estimates of Expense Ratio\\nby Education Level\",\n    subtitle = \"95% and 99% quantiles intervals at mean point\",\n    x = \"Education level\",\n    y = \"Expense Ratio\") +\n  \n   theme_minimal() +\n  \n  theme(plot.title = element_text(face = \"bold\", size = 12),\n        plot.subtitle = element_text(size = 10),\n        axis.text.x = element_text(hjust = 1))\n\n\n\n\n\n\n\n\n\nShow the code\ncombined_pivot_data %&gt;%\n  ggplot(aes(x = income_level, \n             y = joviality)) +\n  \n  stat_pointinterval(\n    aes(interval_color = stat(level)),\n    .width = c(0.95, 0.99),\n    .point = mean,\n    .interval = qi,\n    point_color = \"darkred\",\n    show.legend = FALSE) +\n  \n  #Defining the color of the intervals \n  scale_color_manual(\n    values = c(\"blue2\", \"darkgreen\"),\n    aesthetics = \"interval_color\") +\n  \n  labs(\n    title = \"Visualising uncertainty in mean estimates of Joviality\\nby Income Level\",\n    subtitle = \"95% and 99% quantiles intervals at mean point\",\n    x = \"Income level\",\n    y = \"Joviality\") +\n  \n   theme_minimal() +\n  \n  theme(plot.title = element_text(face = \"bold\", size = 12),\n        plot.subtitle = element_text(size = 10),\n        axis.text.x = element_text(hjust = 1))\n\n\n\n\n\n\n\n\n\nShow the code\ncombined_pivot_data %&gt;%\n  ggplot(aes(x = interestGroup, \n             y = Recreation)) +\n  \n  stat_pointinterval(\n    aes(interval_color = stat(level)),\n    .width = c(0.95, 0.99),\n    .point = mean,\n    .interval = qi,\n    point_color = \"darkred\",\n    show.legend = FALSE) +\n  \n  #Defining the color of the intervals \n  scale_color_manual(\n    values = c(\"blue2\", \"darkgreen\"),\n    aesthetics = \"interval_color\") +\n  \n  labs(\n    title = \"Visualising uncertainty in mean estimates of Recreation Expenses\\nby Interest Group\",\n    subtitle = \"95% and 99% quantiles intervals at mean point\",\n    x = \"Interest Group\",\n    y = \"Recreation\") +\n  \n   theme_minimal() +\n  \n  theme(plot.title = element_text(face = \"bold\", size = 12),\n        plot.subtitle = element_text(size = 10),\n        axis.text.x = element_text(hjust = 1))\n\n\n\n\n\n\n\n\nAs noted from previous section, the only worthy insights drawn here is that higher Education Level have higher uncertainties in terms for Total Annual Income."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#correlation-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#correlation-analysis",
    "title": "Take Home Exercise 1",
    "section": "4.4 Correlation Analysis",
    "text": "4.4 Correlation Analysis\nNext, we plot a correlation chart to compare the different variables. The correlation charts illustrate that there is a positive relationship between Total Expenses and Joviality, as well as Recreation Expenses and Joviality, with Total Expenses having a stronger correlation. That is, the more a user spends, the happier they are. This is previously noted in Section 4.2.2 as well. However, there is a weak positive relationship between Income and Recreation Expenses - that is, the intuitive notion that as one’s spending power increases, one would be spending more on recreation activities is not exactly true.\n\nIncome vs Recreation ExpensesRecreation Expenses vs JovialityTotal Expenses vs Joviality\n\n\n\n\nShow the code\nggscatterstats(\n  data = combined_pivot_data,\n  x = total_income,\n  y = Recreation,\n  marginal = FALSE,\n  )+\n  \n  theme_minimal() +\n  \n  labs(title = 'Correlation of Income and Recreation Expenses', x = \"Annual Income\", y = \"Recreation Expenses\")\n\n\n\n\n\n\n\n\n\nShow the code\nggscatterstats(\n  data = combined_pivot_data,\n  x = Recreation,\n  y = joviality,\n  marginal = FALSE,\n  ) +\n\n  theme_minimal() +\n  \n  labs(title = 'Correlation of Recreation Expense and Joviality Score', x = \"Recreation Expenses\", y = \"Joviality\")\n\n\n\n\n\nShow the code\n        axis.title = element_text(size = 12, face = \"bold\") +\n  theme(text = element_text(family = \"Garamond\"),\n        plot.title = element_text(hjust = 0.2, size = 15, face = 'bold'))\n\n\n\n\n\n\nShow the code\nggscatterstats(\n  data = combined_pivot_data,\n  x = total_expenses,\n  y = joviality,\n  marginal = FALSE,\n  ) +\n\n  theme_minimal() +\n  \n  labs(title = 'Correlation of Total Expense and Joviality Score', x = \"Total Expenses\", y = \"Joviality\")\n\n\n\n\n\nShow the code\n        axis.title = element_text(size = 12, face = \"bold\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#further-analysis---low-income-family",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#further-analysis---low-income-family",
    "title": "Take Home Exercise 1",
    "section": "4.5 Further analysis - Low Income Family",
    "text": "4.5 Further analysis - Low Income Family\nWe wanted to further look into visualising the expenditures of low income family, as this could be an area of interest for City Planners with regards to awarding grants.\nHence, below, we plot a histogram for each of the expense category, where participants from low-income family spend a percentage of their expenses from.\nThe histogram is plotted with ggplot while the coordinated multiple views is augmented with ggiraph.\n\nHistogramCoordinated Multiple Views\n\n\n\n\nShow the code\n# Filter the dataset for low-income participants\nlow_income_data &lt;- combined_pivot_data[combined_pivot_data$income_level == \"Low\", ]\n\n# Calculate the total expenses for each participant\nlow_income_data$total_expenses &lt;- rowSums(low_income_data[, c(\"Recreation\", \"Shelter\", \"Food\", \"Education\")])\n\n# Calculate the percentage spent on recreation for each participant\nlow_income_data$Recreation_pct &lt;- low_income_data$Recreation / low_income_data$total_expenses * 100\nlow_income_data$Shelter_pct &lt;- low_income_data$Shelter / low_income_data$total_expenses * 100\nlow_income_data$Food_pct &lt;- low_income_data$Food / low_income_data$total_expenses * 100\nlow_income_data$Education_pct &lt;- low_income_data$Education / low_income_data$total_expenses * 100\n\n# Combine the three histograms into one plot\nggplot(low_income_data) +\n  geom_histogram(aes(x = Recreation_pct, fill = \"Recreation\"), binwidth = 5, alpha = 0.5) +\n  geom_histogram(aes(x = Shelter_pct, fill = \"Shelter\"), binwidth = 5, alpha = 0.5) +\n  geom_histogram(aes(x = Food_pct, fill = \"Food\"), binwidth = 5, alpha = 0.5) +\n  geom_histogram(aes(x = Education_pct, fill = \"Education\"), binwidth = 5, alpha = 0.5) +\n  scale_fill_manual(values = c(\"Recreation\" = \"steelblue\", \"Shelter\" = \"orange\", \"Food\" = \"green\", \"Education\" = \"yellow\")) +\n  labs(x = \"Percentage over Total Expenses\", y = \"Number of Participants\", fill = \"Expense Category\") +\n  ggtitle(\"Distribution of Percentage Spent on Expenses (Low Income)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\np1 &lt;- ggplot(data=low_income_data, \n       aes(x = Recreation_pct)) +\n  geom_dotplot_interactive(              \n    aes(data_id = participantId),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,60)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=low_income_data, \n       aes(x = Shelter_pct)) +\n  geom_dotplot_interactive(              \n    aes(data_id = participantId),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,60)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\np3 &lt;- ggplot(data=low_income_data, \n       aes(x = Food_pct)) +\n  geom_dotplot_interactive(              \n    aes(data_id = participantId),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(25,80)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\np4 &lt;- ggplot(data=low_income_data, \n       aes(x = Education_pct)) +\n  geom_dotplot_interactive(              \n    aes(data_id = participantId),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,60)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 / p2 | p3 / p4), \n       width_svg = 8,\n       height_svg = 8,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\n\n\n\n\nFrom the above, we could observe that low income family participants are still allocating a larger proportion of their expenses to Recreation expenses, and more so than food."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "title": "Take-Home_Ex03",
    "section": "",
    "text": "pacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, graphlayouts, ggforce, tidytext, tidyverse)\n\nmc3_nodes &lt;- as_tibble(mc3_data$nodes) %&gt;% # distinct() %&gt;% mutate(country = as.character(country), id = as.character(id), product_services = as.character(product_services), revenue_omu = as.numeric(as.character(revenue_omt)), type = as.character(type)) %&gt;% select(id, country, type, revenue_omu, product_services) #don’t use unleash or unnest\n```\ntext snesing with tidytext simple word count tokenisation\nword teonisation with removing stopwords stemming"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "FishEye International is helping the country of Oceanus in identifying companies that has possible engaged in illegal, unreported, and unregulated (IUU) fishing. FishEye has transformed the trade (import/export) data for Oceanus’ marine and fishing industries and transformed it into a knowledge graph. Using this knowledge graph, they hope to understand business relationships, including finding links that will help them stop IUU fishing and protect marine species that are affected by it.\nWith reference to Mini-Challenge 2 of VAST Challenge 2023 and by using appropriate static and interactive statistical graphics methods, this analysis seek to help FishEye identify companies that may be engaged in illegal fishing by focusing on below tasks:\nUse visual analytics to identify temporal patterns for individual entities and between entities in the knowledge graph FishEye created from trade records and (in an attempt to dive deeper) evaluating which the sets of predicted knowledge graph links FishEye has provided are the most reliable."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#install-r-packages",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#install-r-packages",
    "title": "Take Home Exercise 2",
    "section": "3.1 Install R Packages",
    "text": "3.1 Install R Packages\nThe R packages are installed using pacman::p_load(). Below is a list of main packages installed:\njsonlite: Lightweight JSON encoder and decoder for R.\ntidygraph: Tidy interface for graph manipulation and analysis.\ntidyverse: Comprehensive collection of data manipulation and visualization packages.\nggraph: Builds on top of ggplot2 package nad provides a grammar of graphics for plotting graphs and networks.\nigraph: Network analysis and visualization\nplotly: Interactive data visualization package for creating dynamic charts.\nggstatsplot: Enhances ggplot2 with statistical visualization capabilities.\nvisNetwork: Interactive network visualizations.\nheatmaply: Interactive heatmaps with plotly.\ntreemap: Visualize hierarchical data using nested rectangles.\ntreemapify: Create treemaps with ggplot2.\ngganimate: Creates animated plots using ggplot2.\n\npacman::p_load(jsonlite, tidyverse, tidygraph, ggraph, igraph, plotly, visNetwork, heatmaply, treemap, treemapify, gganimate, patchwork, scales)\n\noptions(scipen = 999) #disables scientific notation\n\n\n\n\n\n\n\nTip\n\n\n\nAs the numeric values of the following data set are huge, options(scipen = 999) allows setting of the display format for numeric values. It prevents R from automatically switching to scientific notation."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#loading-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#loading-data",
    "title": "Take Home Exercise 2",
    "section": "3.2 Loading Data",
    "text": "3.2 Loading Data\nAs the datasets provided are in json format, fromJSON function from jsonlite package will be used to import the data. The Main Graph will be imported first, followed by the individual bundles.\n\n3.2.1 Main Graph\n\nmc2_data &lt;- fromJSON(\"data/mc2_challenge_graph.json\")\nglimpse(mc2_data)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     : Named list()\n $ nodes     :'data.frame': 34576 obs. of  4 variables:\n  ..$ shpcountry: chr [1:34576] \"Polarinda\" NA \"Oceanus\" NA ...\n  ..$ rcvcountry: chr [1:34576] \"Oceanus\" NA \"Oceanus\" NA ...\n  ..$ dataset   : chr [1:34576] \"MC2\" \"MC2\" \"MC2\" \"MC2\" ...\n  ..$ id        : chr [1:34576] \"AquaDelight Inc and Son's\" \"BaringoAmerica Marine Ges.m.b.H.\" \"Yu gan  Sea spray GmbH Industrial\" \"FlounderLeska Marine BV\" ...\n $ links     :'data.frame': 5464378 obs. of  9 variables:\n  ..$ arrivaldate     : chr [1:5464378] \"2034-02-12\" \"2034-03-13\" \"2028-02-07\" \"2028-02-23\" ...\n  ..$ hscode          : chr [1:5464378] \"630630\" \"630630\" \"470710\" \"470710\" ...\n  ..$ valueofgoods_omu: num [1:5464378] 141015 141015 NA NA NA ...\n  ..$ volumeteu       : num [1:5464378] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ weightkg        : int [1:5464378] 4780 6125 10855 11250 11165 11290 9000 19490 6865 19065 ...\n  ..$ dataset         : chr [1:5464378] \"MC2\" \"MC2\" \"MC2\" \"MC2\" ...\n  ..$ source          : chr [1:5464378] \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" \"AquaDelight Inc and Son's\" ...\n  ..$ target          : chr [1:5464378] \"BaringoAmerica Marine Ges.m.b.H.\" \"BaringoAmerica Marine Ges.m.b.H.\" \"-15045\" \"-15045\" ...\n  ..$ valueofgoodsusd : num [1:5464378] NA NA NA NA NA ...\n\n\nUsing glimpse() function of the dplyr package, it can be observed that it is a directed multigraph with a nodes and links dataframes. Hence, in the following data wrangling steps, the two dataframes would be extracted individually."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#data-wrangling",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#data-wrangling",
    "title": "Take Home Exercise 2",
    "section": "3.3 Data Wrangling",
    "text": "3.3 Data Wrangling\n\n3.3.1 Tibble Dataframe - Main Graph\nBelow code chunks are used to extract the nodes and edges data tables from the mc2_data list object and saving the outputs in a tibble data frame object named mc2_nodes and mc2_edges_raw respectively.\n\n#Extracting Nodes\nmc2_nodes &lt;- as_tibble(mc2_data$nodes) %&gt;%\n  select(id, shpcountry, rcvcountry)\n\n\n#Extracting edges\nmc2_edges_raw &lt;- as_tibble(mc2_data$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu, \n         volumeteu, weightkg, valueofgoodsusd)\n\n\n\n\n\n\n\nTip\n\n\n\nThe select() function is part of the dplyr package and is used to select specific columns as well as re-organise the sequence of the table.\n\n\n\n\n3.3.2 Other data pre-processing\nBelow are the other data wrangling steps before preparing the data.\nFirstly, duplicated data from both mc2_nodes and mc2_edges_raw tibble dataframe are removed using duplicated() function.\n\n# Remove duplicates from nodes dataframe\nmc2_nodes &lt;- mc2_nodes[!duplicated(mc2_nodes), ]\nglimpse(mc2_nodes)\n\nRows: 34,576\nColumns: 3\n$ id         &lt;chr&gt; \"AquaDelight Inc and Son's\", \"BaringoAmerica Marine Ges.m.b…\n$ shpcountry &lt;chr&gt; \"Polarinda\", NA, \"Oceanus\", NA, \"Oceanus\", \"Kondanovia\", NA…\n$ rcvcountry &lt;chr&gt; \"Oceanus\", NA, \"Oceanus\", NA, \"Oceanus\", \"Utoporiana\", NA, …\n\n\n\n# Remove duplicates from links dataframe\nmc2_edges_raw &lt;- mc2_edges_raw[!duplicated(mc2_edges_raw), ]\nglimpse(mc2_edges_raw)\n\nRows: 5,309,087\nColumns: 8\n$ source           &lt;chr&gt; \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son…\n$ target           &lt;chr&gt; \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica M…\n$ arrivaldate      &lt;chr&gt; \"2034-02-12\", \"2034-03-13\", \"2028-02-07\", \"2028-02-23…\n$ hscode           &lt;chr&gt; \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"47…\n$ valueofgoods_omu &lt;dbl&gt; 141015, 141015, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ volumeteu        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ weightkg         &lt;int&gt; 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, …\n$ valueofgoodsusd  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 87110, 188140, NA, 221110, 58…\n\n\nThe mc2_nodes data frame has no duplicates whereas the mc2_edges_raw data frame was de-duplicated from 5,464,378 rows to 5,309,087 unique rows.\n\n\n\n\n\n\nTip\n\n\n\nThe above uses the duplicated() function to identify duplicated rows, and the ! operator is used to select the rows that are not duplicated, keeping only the first occurence of each unique row. Another alternative is to use distinct()function from the dplyr package. Both achieve the same outcome, except the distinct() is typically used when creating a new dataframe.\n\n\nNext, considering value of goods fields would be an important edge metrics to analyse, we shall remove rows that have NA values for both valueofgoods_omu and valueofgoodsusd, considering we yet to know the difference of both and assuming every row should have either one.\nis.na() function to identify rows with NA values, and the ! operator is used to select the rows that have no NA values.\n\n# Remove records with NA values in both 'valueofgoods_omu' and 'valueofgoodsusd' columns\nmc2_edges_raw &lt;- mc2_edges_raw[!(is.na(mc2_edges_raw$valueofgoods_omu) & is.na(mc2_edges_raw$valueofgoodsusd)), ]\n\nNext, we want to add the shipping country and receiver country of the source company and target company of each edges respectively into the mc2_edges_raw dataframe. To do this, we perform a two-step processing using merge() function where we join both the mc2_nodes dataframe to mc2_edges_raw dataframe on the id column of the former, and the target column of the latter. This creates a new dataframe called mc2_edges_merge_rcr. Next, we do the same with mc2_nodes and the new mc2_edges_merge_rcr, but this time joining on the source column. Since we joined the dataframes twice, the 2 additional columns added are removed.\n\n# Left join mc2_nodes to mc2_edges_raw to add receiver country (shipping country is removed here as it is the shipping country of the target company)\nmc2_edges_merge_rcr &lt;- merge(mc2_edges_raw, mc2_nodes, by.x = \"target\", by.y = \"id\", all.x = TRUE)[,-c(9)]\n# Left join mc2_nodes to mc2_edges_merge_rcr to add shipping country (receiver country is removed here as it is the receiver country of the source company)\nmc2_edges_merge_shp &lt;- merge(mc2_edges_merge_rcr, mc2_nodes, by.x = \"source\", by.y = \"id\", all.x = TRUE)[,-c(11)]\n\n\n\n\n\n\n\nTip\n\n\n\nThe above uses the merge() function to perform the left join operation instead of left_join() function in dplyr package. This is because left_join() requires both tables to be joined on a common column. In our case, we require the mc2_node’s id column to be left joined to source and target column of mc2_edges_raw respectively. Hence merge() is more appropriate here.\n\n\nLastly, we performed below steps on the edges table:\n\nfilter() is used to select records where either the shipping or receiver country is “Oceanus”. As the purpose of the case at hand is to analyse for the Country of Oceanus, we presume only the shipping trade records that involved Country of Oceanus are pertinent here.\nrename() is used to rename the generic column name rcvcountry.x to rcvcountry\nmutate() is used several times to create derived fields as well as convert the data format\n\nymd() of lubridate package is used to covert arrivaldate field from character data type into date data type\nformat() is used to convert ArrivalDate field into year and month values separately\n`substr()` is used to extract the first 2 digits of HSCode field, which is used to group the Chapters of the HSCodes. as.factor() is then used to convert it to a factor format.\n\nselect() is used not only to select the field needed but also to re-ogranise the sequence of the fields.\n\n\nmc2_edges &lt;- mc2_edges_merge_shp %&gt;% \n  filter(rcvcountry.x == \"Oceanus\" | shpcountry == \"Oceanus\") %&gt;% #removing rows where the target or source companies' associated country are not 'Oceanus'\n  rename(rcvcountry = rcvcountry.x)%&gt;% #renaming default column name resulted from merge() function in previous step\n  mutate(ArrivalDate = ymd(arrivaldate)) %&gt;% #convert the arrival date to a date format\n  mutate(Year = format(ArrivalDate, \"%Y\")) %&gt;% #extract the year from the arrival date\n  mutate(month = format(ArrivalDate, \"%b\"))%&gt;% #extract the month from the arrival date\n  mutate(hscode_2digits = as.factor(substr(hscode,1,2))) %&gt;% #extract the year from the arrival date\n  mutate(hscode = as.factor(hscode))%&gt;% #convert hscode to factor format\n  select(source, target, ArrivalDate, Year, month, hscode, hscode_2digits, valueofgoods_omu, \n         volumeteu, weightkg, valueofgoodsusd, shpcountry, rcvcountry) #select the columns that we want to keep"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#main-graph-1",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#main-graph-1",
    "title": "Take Home Exercise 2",
    "section": "4.1 Main Graph",
    "text": "4.1 Main Graph\n\n4.1.1 HScodes and Importers/Exporters over the years\nFrom the plot below, it could be observed that there are about 3000-4000 HSCodes every year, and more than 9000 importers{style=“color:#CF9A7A;”}/exporters{style=“color:#8EA8BD;”} on a yearly basis. Hence it could be quite difficult to derive any meaningful analysis if the entire dataset is plotted in a graph. In addition, the data is stretched from a 6-year period from 2028 to 2034.\nggplot() function is used to initialise the bar chart, and the 2 charts are combined to a composite figure using patchwork, a ggplot2 extension.\n\n\nShow the code\n# Create a bar plot\nhscodes_p1 &lt;- mc2_edges %&gt;%\n  group_by(Year) %&gt;%\n  summarize(num_hscodes = n_distinct(hscode))%&gt;%\n  ggplot(aes(x = Year, y = num_hscodes)) +\n  geom_bar(stat = \"identity\", fill = '#808de8') +\n  labs(x = \"Year\", y = \"Number of HSCodes\", subtitle = \"Number of HSCodes per Year\") +\n  theme_minimal()+\n  theme(panel.grid.major = element_blank(),  # Remove vertical gridlines\n        panel.grid.minor = element_blank(),  # Remove horizontal gridlines\n        plot.subtitle = element_text(color = \"dimgrey\", size = 12, hjust = 0.5,face = 'bold'))  # Center the ggtitle\n\ntrade_p2 &lt;- mc2_edges %&gt;%\n  group_by(Year) %&gt;%\n  summarize(num_importers = n_distinct(target),\n            num_exporters = n_distinct(source))%&gt;%\n  ggplot(aes(x = Year)) +\n  geom_bar(aes(y = num_importers), stat = \"identity\", fill = \"#CF9A7A\") +\n  geom_bar(aes(y = num_exporters), stat = \"identity\", fill = \"#8EA8BD\") +\n  labs(x = \"Year\", y = \"Count\", subtitle = \"Number of Importers & Exporters\\nOver the Years\")+\n  theme_minimal()+\n  theme(panel.grid.major = element_blank(),  # Remove vertical gridlines\n        panel.grid.minor = element_blank(),  # Remove horizontal gridlines\n        plot.subtitle = element_text(color = \"dimgrey\", size = 12, hjust = 0.5,face = 'bold'))  # Center the ggtitle\n\nhscodes_p1 + trade_p2\n\n\n\n\n\n\n\n4.1.2 Trade Records\nNext, we’re interested to find out the number of trade records that occured throughout the years. Particularly, we would like to find out which particular Year or Month have the higher trade records and if there are any temporal patterns. In order to visualise this trend, we’ve opt to use Heatmap.\nIn order to plot a heatmap, we first need to transform the data in the data fram into a data matrix using data.matrix(). heatmaply is then used to build an interactive heatmap. In our case below, clustering of the transactions throughout the year is not of utmost importance, hence we have remove the clustering of heatmaply by setting dendrogram = \"none\".\nFrom the Trade Records heatmap, it could be observed that number of trade records are highest in Year 2030, and there seem to be a decreasing number of transactions over the years after. Particularly, trade records are highest on Aug 2030.\n\n\nShow the code\n## Heatmap of trade records over the months\n\n# Count the number of transactions per month and year\ntransactions_count &lt;- mc2_edges %&gt;%\n  group_by(month, Year) %&gt;%\n  summarize(count = n())\n\n# Reshape the data to wide format for heatmap\nheatmap_data &lt;- transactions_count %&gt;%\n  pivot_wider(names_from = Year, values_from = count, values_fill = 0)\n\n# Convert the data to a matrix using data.matrix\nheatmap_matrix &lt;- data.matrix(heatmap_data)\n\n# Create a separate matrix or data frame with custom tooltip text\ntooltip_text &lt;- data.matrix(paste(\"Year:\", colnames(heatmap_data)[-1], \"\\nMonth:\", heatmap_data$month))\n\n# Create the interactive heatmap using heatmaply\nheatmaply(heatmap_matrix[, -c(1)], #remove first column\n          dendrogram = \"none\", #remove cluster\n          colors = Blues,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 8,\n          fontsize_col = 8,\n          main=\"Trade Records over the years\",\n          xlab = \"Months\",\n          ylab = \"Years\",\n          )\n\n\n\n\n\n\n\n\n4.1.3 Weight vs Volume\nNext, in order to identify which HSCodes are of particular meaning, we plotted a scatterplot of the median weight of the HSCodes vs median Value of goods to observe if there are any particular insights that could be drawn. This is plotted following the assumption that HSCodes with highest value and lowest weight would be more incentivising for companies to partake in illegal trading.\nHSCodes of Chapter 29 here stands out the most as the highest value and lowest weight.\n\n\nShow the code\n# Creating separate datatable\nhscodes_breakdown &lt;- mc2_edges %&gt;%\n  group_by(hscode_2digits) %&gt;%\n  summarize(avg_value = mean(valueofgoodsusd, na.rm = TRUE),\n            avg_weight = mean(weightkg, na.rm = TRUE))\n\n#Configuring custom tooltip\nhscodes_breakdown$tooltip &lt;- c(paste0(\"Hscode = \", hscodes_breakdown$hscode_2digits))\n\n# Create the scatter plot\ng &lt;- ggplot(hscodes_breakdown, aes(x = avg_weight, y = avg_value, text = tooltip)) +\n  geom_point(color = '#3498DB') +\n  labs(x = \"Weight\", y = \"Value of Goods\") +\n  ggtitle(\"Scatter Plot: Value of Goods vs. Weight\") +\n  theme_classic()+\n  theme(plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n        axis.title = element_text(size = 11),\n        axis.text = element_text(size = 11),\n        panel.grid.minor = element_blank())+\n    scale_y_continuous(labels = label_number(suffix = \" M\", scale = 1e-6)) + # millions\n    scale_x_continuous(labels = label_number(suffix = \" M\", scale = 1e-6)) # millions\n\n\nggplotly(g)\n\n\n\n\n\n\n\n\n4.1.4 HSCodes Breakdown\nNext, we look to explore and visualise the different types of HSCodes for the trade records, in a bid to understand which HSCodes are most widely used. In order to do so, we will use a Treemap visualisation.\nWe first perform steps to manipulate and prepare a dataframe that is appropriate for treemap visualisation:\n\ngroup trade records by HSCode_2digits (HSCodes Chapters) and HSCodes\nCompute the number of trade records, median value of goods, and median weight\n\nNext, as there are over 4000 unique HSCodes every year which might not be useful for visualisation, we use quantile to extract the top 10 percentile of HSCodes by trade records. Lastly, we use treemap to create a static treemap, and followed by d3tree() function for an interactive version.\n\nStaticInteractive\n\n\n\n\nShow the code\n#creating a dataframe appropriate for treemap visualtions\nhscodes_breakdown &lt;- mc2_edges %&gt;%\n  group_by(hscode_2digits, hscode) %&gt;%\n  summarise(count = n(),\n            Median_Value = median(valueofgoodsusd, na.rm = TRUE),\n            Median_weight = median(weightkg, na.rm = TRUE)\n            )\nhscodes_breakdown &lt;- na.omit(hscodes_breakdown)\n\n# Calculate the threshold for the top 10% count\ncount_threshold &lt;- quantile(hscodes_breakdown$count, probs = 0.9)\n\n#Filtering only top 10%\nhscodes_breakdown_top10 &lt;- hscodes_breakdown[hscodes_breakdown$count &gt;= count_threshold, ]\n\nhscode_tm &lt;- treemap(hscodes_breakdown_top10,\n                     index=c(\"hscode_2digits\", \"hscode\"),\n                     vSize=\"count\", #configure size by number of trade records\n                     vColor=\"Median_Value\", #configure color by median value of the trade records by HSCode \n                     type = \"value\",\n                     title=\"HSCodes Breakdown\",\n                     title.legend = \"Median Value of Goods (USD)\"\n                     )\n\n\n\n\n\n\n\n\n\nShow the code\nlibrary(devtools)\n#install_github(\"timelyportfolio/d3treeR\")\nlibrary(d3treeR)\n\nd3tree(hscode_tm,rootname = \"HSCodes\" )\n\n\n\n\n\n\n\n\n\nFrom the above, it can be observe the HSCode Chapter 3 represented the highest number of trade records for the dataset. This could mean that trade records under this Chapter is of particular importance (could mean a commodity like fishes, food, etc.), hence this Chapter could be of particular interest in following analysis."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#preparing-edges-data-table",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#preparing-edges-data-table",
    "title": "Take Home Exercise 2",
    "section": "5.1 Preparing edges data table",
    "text": "5.1 Preparing edges data table\nBased on the EDA performed in previous section, we will filter the large dataset by HSCode_2digits = 30 and Year = 2030 in order to deep dive further into the interactions between the different nodes.\n\n# filter the edges dataframe to only include the edges that are in the year 2030 and the hscode is 30\nmc2_edges_aggregated &lt;- mc2_edges %&gt;%\n  filter(hscode_2digits == \"30\" & Year == \"2034\") %&gt;%\n  group_by(source, target, hscode, Year) %&gt;%\n  summarise(weights = n()) %&gt;% # summarise the weights by counting the number of edges\n  filter(source!=target) %&gt;%  # filter out the edges that have the same source and target\n  filter(weights &gt; 20) %&gt;%  # filter out the edges that have weights less than 20\n  ungroup()  # ungroup the dataframe"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#preparing-nodes-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#preparing-nodes-data",
    "title": "Take Home Exercise 2",
    "section": "5.2 Preparing nodes data",
    "text": "5.2 Preparing nodes data\nNext, we will prepare a new nodes data table that is derived from the source and target fields of mc2_edges_aggregrated data table to ensure that the nodes in the nodes data table include all the source and target values of the edges table.\nIn below code chunk, we extract the source values and target values from mc2_edges_aggregated data table separately, combined them, and then obtain the unique values using distinct().\nLastly, we filter the original mc2_nodes data table based on this new list, instead of using this new list as the node data so as to still retain the attributes of the nodes which are only available in mc2_nodes.\n\n# extract the source column from the edges dataframe and rename it to id1\nid1 &lt;- mc2_edges_aggregated %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\n# extract the target column from the edges dataframe and rename it to id2\nid2 &lt;- mc2_edges_aggregated %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\n# combine the id1 and id2 dataframes and remove the duplicates\nmc2_nodes_list &lt;- rbind(id1, id2) %&gt;%\n  distinct()\n# filter the nodes dataframe to only include the nodes that are in the mc2_nodes_list\nmc2_nodes_extracted &lt;- mc2_nodes %&gt;%\n  filter(id %in% mc2_nodes_list$id)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#build-tidy-graph-data-model",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#build-tidy-graph-data-model",
    "title": "Take Home Exercise 2",
    "section": "5.3 Build tidy graph data model",
    "text": "5.3 Build tidy graph data model\nBelow code chunk is used to build the tidy graph data model using tbl_graph() function.\n\n# create a graph from the nodes and edges dataframes\nmc2_graph &lt;- tbl_graph(nodes = mc2_nodes_extracted,\n                       edges = mc2_edges_aggregated,\n                       directed = TRUE)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#plotting-of-trade-interactions-using-eigenvector-centrality",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#plotting-of-trade-interactions-using-eigenvector-centrality",
    "title": "Take Home Exercise 2",
    "section": "6.1 Plotting of trade interactions using Eigenvector Centrality",
    "text": "6.1 Plotting of trade interactions using Eigenvector Centrality\nAs there are still a huge number of edges and nodes, we will focus only on the top 10% nodes based on their eigenvecotr centrality score. The eigenvector centrality score is first computed within mc2_graph, and the quantile function is used to extract the top 10 percentile of nodes based on the eigenvector centrality score. In addition, to visualise if there are any community among the nodes, we use community detection algorithms built in tidygraph package. In particular, we used group_edge_betweenness() function to identify groups or communities within a network where nodes are more densely connected within the same group than with nodes in other groups. visNetwork() is then use to create an interactive graph. For better visualisation, the top 5 percentile of nodes by Eigenvector centrality score are distinctly coloured.\n\n\nShow the code\n# add a column to the graph that contains the eigen centrality of each node\nmc2_graph_eigen &lt;- mc2_graph %&gt;%\n  mutate(eigen_centrality = centrality_eigen())\n\n# Filter nodes based on eigen_centrality\ntop_nodes &lt;- mc2_graph_eigen %&gt;%\n  activate(nodes) %&gt;%\n  as.data.frame() %&gt;%\n  filter(eigen_centrality &gt;= quantile(eigen_centrality, 0.9))\n\n# Filter edges based on top_nodes\nmc2_edges_eigen &lt;- mc2_edges_aggregated %&gt;%\n  filter(source %in% top_nodes$id | target %in% top_nodes$id)\n\n#Re-extracting nodes from filtered edges\nid1_eigen &lt;- mc2_edges_eigen %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2_eigen &lt;- mc2_edges_eigen %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nmc2_nodes_eigen_list &lt;- rbind(id1_eigen, id2_eigen) %&gt;%\n  distinct()\nmc2_nodes_extracted_eigen &lt;- mc2_graph_eigen %&gt;%\n  activate(nodes) %&gt;%\n  as.data.frame() %&gt;%\n  filter(id %in% mc2_nodes_eigen_list$id)\n\n# Create the subgraph with top nodes and edges\nsubgraph &lt;- tbl_graph(nodes = mc2_nodes_extracted_eigen, edges = mc2_edges_eigen, directed = TRUE)\n\n#Creating the edges dataframe \nedges_df &lt;- subgraph %&gt;%\n  activate(edges) %&gt;%\n  as.tibble()\n\n#Creating the nodes dataframe \nnodes_df &lt;- subgraph %&gt;%\n  mutate(community = group_edge_betweenness(weights = weights, directed = TRUE)) %&gt;% #computing community score\n  activate(nodes) %&gt;%\n  as_tibble() %&gt;%\n  rename(name = id) %&gt;%\n  mutate(id=row_number())\n\n\n#Manual configuration of the nodes' attribute for graph visualisation\nnodes_df &lt;- nodes_df %&gt;%\n  mutate(color = ifelse(eigen_centrality &gt;= quantile(nodes_df$eigen_centrality, 0.95), \"#B7245C\", \"#395B50\"),\n         title = paste0(\"&lt;b&gt;&lt;br&gt;&lt;span style='color: black;'&gt;\",id, \": \", name,\"&lt;/b&gt;&lt;/span&gt;&lt;p&gt;\"),\n         label = name,\n         size = eigen_centrality*100\n         )\n\n#Interactive Graph\nvisNetwork(nodes_df,\n           edges_df,\n           height = \"500px\", width = \"100%\") %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows =list(to = list(enabled = TRUE, scaleFactor = 2)),\n           color = list(color = \"gray\", highlight = \"#7C3238\"),\n           width = 2\n           )%&gt;%\n  visNodes(\n    borderWidth = 1,\n    shadow = TRUE,\n  ) %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE,\n             selectedBy =\"community\", #allow filtering of nodes based on Community\n             ) %&gt;%\n  visLayout(randomSeed = 123) # to have always the same network   \n\n\n\n\n\n\nFrom the above, we could observe that the nodes with the higher eigenvector values (i.e.Mar del Este CJSC, hǎi dǎn Corporation Wharf, Caracola del Sol Services) all have the same traits:\n\nThey are all import hubs where they only have in-degree edges.\nThey are do trades with other companies/nodes with higher eigenvector values.\nThey belong in the same community (Community = 1)\n\n\n\n\n\n\n\nTip\n\n\n\nEigenvector centrality (computed using centrality_eigen() function from tidygraph) is a measure of the influence or importance of a node in a network. It takes into account both the node’s direct connections and the connections of its connected partners. This would allow us to observe which company has the highest level of influence in the trade network.\nBetweenness centrality (computed using centrality_betweenness() function from tidygraph) is also a relevant centrality measure especially for trade networks. It is calculated by counting the number of shortest paths that pass through that node, and hence is useful to see which companies are critical connectors within the network, which could indicate them being intermediaries or brokers in the shipping network.\nA similar plot as done with Betweenness Centrality measure, however, most of the nodes have 0 betweenness centrality score, which could indicate that within this HSCode, the nodes mostly connect with each other. Hence, we will focus more on eigenvector centrality measure."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#communities-within-the-network",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#communities-within-the-network",
    "title": "Take Home Exercise 2",
    "section": "6.2 Communities within the network",
    "text": "6.2 Communities within the network\nGiven the plot from the above graph generated 251 communities, most of each are isolated communities and does not provide much insights, we will further filter the data. In particular, we will filter by HSCode = 306170, the HSCode with the highest number of trade records.\nFrom the below, we can observe the within the HSCodes, there are distinct and clear communities within the network, with a particular community that stands out being the biggest. In addition, there are also other communities that are isolated and not connected to the main network.\n\n\nShow the code\n#Creating a separate edge list filter by hscode = 306170\nmc2_edges_hscode&lt;- mc2_edges %&gt;%\n  filter(hscode == \"306170\" & Year == \"2030\") %&gt;%\n  mutate(Year = as.factor(Year)) %&gt;% #extract the year from the arrival date\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 20) %&gt;%\n  ungroup()\n\n#Extracting Nodes\nid1_hscode &lt;- mc2_edges_hscode %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2_hscode &lt;- mc2_edges_hscode %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nmc2_nodes_hscode &lt;- rbind(id1_hscode, id2_hscode) %&gt;%\n  distinct()\nmc2_nodes_hscode_extracted &lt;- mc2_nodes %&gt;%\n  filter(id %in% mc2_nodes_hscode$id)\n\n# Create the subgraph with top nodes and edges\nsubgraph_hscode &lt;- tbl_graph(nodes = mc2_nodes_hscode_extracted,\n                       edges = mc2_edges_hscode,\n                       directed = TRUE)\n\ng &lt;- subgraph_hscode %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = weights, directed=TRUE))) %&gt;%\n  mutate(id_num=row_number()) %&gt;%\n  ggraph(layout = \"kk\") + \n  geom_edge_link(aes(width=weights), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(size=centrality_eigen(), color = community),show.legend = FALSE)+ #set node size by eigenvector score and color by community\n  geom_node_text(aes(label = ifelse(centrality_eigen() &gt;= quantile(centrality_eigen(),0.95), id_num, \"\")), size = 3, nudge_y = 0,fontface = \"bold\") + #only labelling the top 5 percentile of nodes\n  ggtitle(\"Network Graph of HSCode 306170 in Year 2030\")\ng + theme_graph() + theme(plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#temporal-graph-of-top-nodes",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#temporal-graph-of-top-nodes",
    "title": "Take Home Exercise 2",
    "section": "6.3 Temporal Graph of Top Nodes",
    "text": "6.3 Temporal Graph of Top Nodes\nTo further observe the temporal patterns of the network, we further filter the nodes by the few observable nodes identified in 6.1. Next, we further filter the HSCode by 306170. Lastly, using `gganimate, we plot an animated graph that shows the changes in edges over the years, from Year 2028 to Year 2034.\nFrom the animated chart, it can be observed that the number of edges increased visbily over the years. For example, for 3.Costa de la Felicidad Shipping, it started with one in-degree interaction in year 2028 to numerous in-degree interactions in Year 2034.\n\n\nShow the code\n#Creating a list of top nodes\ntop_10_percentile_nodes  &lt;- c(\"Mar del Este CJSC\", \"Caracola del Sol Services\", \"hǎi dǎn Corporation Wharf\", \"Playa de Arena OJSC Express\",\n               \"Costa de la Felicidad Shipping\", \"Blue Horizon Family &\", \"Selous Game Reserve S.A. de C.V.\",\n               \"Tripura Market S.A. de C.V.\")\n\n#Creating a separate edge list filter by these nodes\nmc2_edges_topnodes &lt;- mc2_edges %&gt;%\n  filter(source %in% top_10_percentile_nodes | target %in% top_10_percentile_nodes) %&gt;%\n  filter(hscode == \"306170\") %&gt;%\n  mutate(Year = as.factor(Year)) %&gt;% #extract the year from the arrival date\n  group_by(source, target, hscode, Year) %&gt;%\n    summarise(weights = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(weights &gt; 20) %&gt;%\n  ungroup()\n\n#Extracting Nodes\nid1 &lt;- mc2_edges_topnodes %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- mc2_edges_topnodes %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nmc2_topnodes_list &lt;- rbind(id1, id2) %&gt;%\n  distinct()\nmc2_topnodes_extracted &lt;- mc2_nodes %&gt;%\n  filter(id %in% mc2_topnodes_list$id)\n\n# Create the subgraph with top nodes and edges\nmc2_graph_topnodes &lt;- tbl_graph(nodes = mc2_topnodes_extracted,\n                       edges = mc2_edges_topnodes,\n                       directed = TRUE)\n\n#plotting graph\ng &lt;- mc2_graph_topnodes %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = weights, directed = TRUE))) %&gt;%\n  mutate(id_num=row_number()) %&gt;%\n  ggraph(layout = \"fr\") +  \n  geom_edge_link(alpha=0.3, arrow =arrow(type = \"closed\")) +\n  scale_edge_width(range = c(0.1, 10)) +\n  geom_node_point(aes(size = centrality_eigen(), color = ifelse(id %in% top_10_percentile_nodes, \"red\",\"grey\")),show.legend = FALSE) +\n  ggtitle(\"Interactions of Top Nodes by Year: {closest_state}\") +\n  geom_node_text(aes(label = ifelse(centrality_eigen() &gt;= quantile(centrality_eigen(),0.95), id_num, \"\")), size = 3, nudge_y = 0,fontface = \"bold\")  #only labelling the top 5 percentile of nodes\n\n\n  \nanimated_graph &lt;- g +\n  theme(plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5)) +\n  transition_states(Year, transition_length = 1, state_length = 1) +\n  enter_fade() +  # Fade in nodes for current year\n  exit_fade()  # Fade out nodes for previous years\n\nanimate(animated_graph, fps = 10, duration = 10)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#loading-the-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#loading-the-data",
    "title": "Take Home Exercise 2",
    "section": "7.1.1 Loading the data",
    "text": "7.1.1 Loading the data\n\nMC2_carp &lt;- fromJSON(\"data/bundles/carp.json\")\nMC2_catfish &lt;- fromJSON(\"data/bundles/catfish.json\")\nMC2_chub_mackerel &lt;- fromJSON(\"data/bundles/chub_mackerel.json\")\nMC2_cod2 &lt;- fromJSON(\"data/bundles/cod2.json\")\nMC2_herring &lt;- fromJSON(\"data/bundles/herring.json\")\nMC2_lichen &lt;- fromJSON(\"data/bundles/lichen.json\")\nMC2_mackerel &lt;- fromJSON(\"data/bundles/mackerel.json\")\nMC2_pollock &lt;- fromJSON(\"data/bundles/pollock.json\")\nMC2_salmon_wgl &lt;- fromJSON(\"data/bundles/salmon_wgl.json\")\nMC2_salmon &lt;- fromJSON(\"data/bundles/salmon.json\")\nMC2_shark &lt;- fromJSON(\"data/bundles/shark.json\")\nMC2_tuna &lt;- fromJSON(\"data/bundles/tuna.json\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#data-wrangling-1",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#data-wrangling-1",
    "title": "Take Home Exercise 2",
    "section": "7.1.2 Data Wrangling",
    "text": "7.1.2 Data Wrangling\nSimilarly, we create the same tibble dataframe for each for the bundle.\n\nCarpCatfishChub MackerelCod2HerringLichenMackerelPollockSalmon_wglSalmonSharkTuna\n\n\n\nMC2_carp_nodes &lt;-as_tibble(MC2_carp$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_carp_edges &lt;-as_tibble(MC2_carp$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu, \n         volumeteu, weightkg, generated_by)\n\n\n\n\nMC2_catfish_nodes &lt;-as_tibble(MC2_catfish$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_catfish_edges &lt;-as_tibble(MC2_catfish$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu,generated_by) #missing volumeteu, weightkg\n\n\n\n\nMC2_chub_mackerel_nodes &lt;-as_tibble(MC2_chub_mackerel$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_chub_mackerel_edges &lt;-as_tibble(MC2_chub_mackerel$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu, \n         volumeteu, weightkg,generated_by)\n\n\n\n\nMC2_cod2_nodes &lt;-as_tibble(MC2_cod2$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_cod2_edges &lt;-as_tibble(MC2_cod2$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu, \n         volumeteu, weightkg,generated_by)\n\n\n\n\nMC2_herring_nodes &lt;-as_tibble(MC2_herring$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_herring_edges &lt;-as_tibble(MC2_herring$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu, \n         volumeteu, weightkg,generated_by)\n\n\n\n\nMC2_lichen_nodes &lt;-as_tibble(MC2_lichen$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_lichen_edges &lt;-as_tibble(MC2_lichen$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu, \n         volumeteu, weightkg,generated_by)\n\n\n\n\nMC2_mackerel_nodes &lt;-as_tibble(MC2_mackerel$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_mackerel_edges &lt;-as_tibble(MC2_mackerel$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu,generated_by) #missing volumeteu, weightkg\n\n\n\n\nMC2_pollock_nodes &lt;-as_tibble(MC2_pollock$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_pollock_edges &lt;-as_tibble(MC2_pollock$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu, \n         volumeteu, weightkg,generated_by)\n\n\n\n\nMC2_salmon_wgl_nodes &lt;-as_tibble(MC2_salmon_wgl$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_salmon_wgl_edges &lt;-as_tibble(MC2_salmon_wgl$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu, \n         volumeteu, weightkg,generated_by)\n\n\n\n\nMC2_salmon_nodes &lt;-as_tibble(MC2_salmon$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_salmon_edges &lt;-as_tibble(MC2_salmon$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu, \n         volumeteu, weightkg,generated_by)\n\n\n\n\nMC2_shark_nodes &lt;-as_tibble(MC2_shark$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_shark_edges &lt;-as_tibble(MC2_shark$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu, \n         volumeteu, weightkg,generated_by)\n\n\n\n\nMC2_tuna_nodes &lt;-as_tibble(MC2_tuna$nodes) %&gt;%\n  select(id,shpcountry,rcvcountry)\nMC2_tuna_edges &lt;-as_tibble(MC2_tuna$links) %&gt;%\n  select(source,target,arrivaldate, hscode,valueofgoods_omu,generated_by) #missing volumeteu, weightkg"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#preparing-edges-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#preparing-edges-data",
    "title": "Take Home Exercise 2",
    "section": "7.1.3 Preparing edges data",
    "text": "7.1.3 Preparing edges data\nIn below code chunk, we combined all the 12 bundles into a combined edge data table to facilitate further analysis.\n\nbundle_edges &lt;- bind_rows(MC2_carp_edges,MC2_chub_mackerel_edges,\n                        MC2_cod2_edges,MC2_herring_edges,MC2_lichen_edges,\n                        MC2_pollock_edges,MC2_salmon_wgl_edges,\n                        MC2_salmon_edges,MC2_shark_edges, \n                        MC2_catfish_edges,MC2_mackerel_edges,MC2_tuna_edges) %&gt;%\n  mutate(ArrivalDate = ymd(arrivaldate)) %&gt;% #convert the arrival date to a date format\n  mutate(Year = format(ArrivalDate, \"%Y\")) %&gt;% #extract the year from the arrival date\n  mutate(hscode_2digits = as.factor(substr(hscode,1,2))) %&gt;%\n  mutate(month = format(ArrivalDate, \"%b\"))%&gt;%\n  mutate(hscode = as.factor(hscode))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#bundle-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#bundle-analysis",
    "title": "Take Home Exercise 2",
    "section": "8.1 Bundle analysis",
    "text": "8.1 Bundle analysis\nFrom below, it can be observed that the bundles output records only have data from 2033-2035, and where only the year 2034 do all the bundle outputs have data. In addition, different bundles have differing number of HSCodes.\n\n\nShow the code\n# Plot for Number of records by year\nrecord_p1 &lt;- bundle_edges %&gt;%\n  group_by(generated_by, Year) %&gt;%\n  summarise(num_records = n()) %&gt;%\n  ggplot(aes(x = Year, y = num_records, fill = generated_by)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(x = \"Year\", y = \"Number of Records\", subtitle = \"Data Available by Year\\nfor each Bundle output\") +\n  scale_fill_brewer(palette = \"Set3\")+\n  theme_minimal()+\n  theme(panel.grid.major = element_blank(),  # Remove vertical gridlines\n        panel.grid.minor = element_blank(),  # Remove horizontal gridlines\n        plot.subtitle = element_text(color = \"dimgrey\", size = 12, hjust = 0.5,face = 'bold'))  # Center the ggtitle\n\n# Plot for number of hscodes per bundle\nhscode_p2 &lt;- bundle_edges %&gt;%\n  group_by(generated_by) %&gt;%\n  filter(hscode_2digits == \"30\") %&gt;%\n  summarise(num_outputs = n_distinct(hscode))%&gt;%\n  ggplot(aes(x = generated_by, y = num_outputs,fill = generated_by)) +\n  geom_bar(stat = \"identity\",show.legend = FALSE) +\n  labs(x = \"Generated By Bundle\", y = \"Number of Outputs\", subtitle = \"Number of Outputs\\nper HSCodes\")+\n  scale_fill_brewer(palette = \"Set3\")+\n  theme_minimal()+\n  theme(axis.text.x=element_blank(), #remove x-axis label\n        panel.grid.major = element_blank(),  # Remove vertical gridlines\n        panel.grid.minor = element_blank(),  # Remove horizontal gridlines\n        plot.subtitle = element_text(color = \"dimgrey\", size = 12, hjust = 0.5,face = 'bold'))  # Center the ggtitle\n\nrecord_p1 + hscode_p2"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#hscode-breakdown",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02_2.html#hscode-breakdown",
    "title": "Take Home Exercise 2",
    "section": "8.2 HSCode Breakdown",
    "text": "8.2 HSCode Breakdown\nUsing similar approach from Section 4, we also breakdown the HSCodes for the combined bundled graph data. Similarly, it could be observed that in the bundled data, HSCode Chapter 30 also has the highest record count.\n\n\nShow the code\n#treemap of hscodes\nbundle_hscodes &lt;- bundle_edges %&gt;%\n  group_by(hscode_2digits, hscode, generated_by) %&gt;%\n  summarise(count = n(),\n            Median_Value = median(valueofgoods_omu, na.rm = TRUE),\n            Median_weight = median(weightkg, na.rm = TRUE)\n            )\nbundle_hscodes &lt;- na.omit(bundle_hscodes)\n\n# Calculate the threshold for the top 10% count\ncount_threshold &lt;- quantile(bundle_hscodes$count, probs = 0.9)\n\n#Filtering only top 10%\nbundle_hscodes_top10 &lt;- bundle_hscodes[bundle_hscodes$count &gt;= count_threshold, ]\n\nhscode_tm &lt;- treemap(bundle_hscodes_top10,\n                     index=c(\"hscode_2digits\", \"hscode\", \"generated_by\"),\n                     vSize=\"count\",\n                     vColor=\"Median_Value\",\n                     type = \"value\",\n                     #palette=\"Blues\", \n                     title=\"HSCodes Breakdown\",\n                     title.legend = \"Median ValueOfGoods (USD)\"\n                     )"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html",
    "title": "In-Class_Ex04",
    "section": "",
    "text": "pacman::p_load(rstatix, gt, patchwork, tidyverse)\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#plot",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#plot",
    "title": "In-Class_Ex04",
    "section": "Plot",
    "text": "Plot\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam_data,\n       aes(sample=ENGLISH)) +\n  stat_qq() + #normal distribution\n  stat_qq_line()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can see that the points deviate significantly from the straight diagonal line"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#plot-patchwork",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex04.html#plot-patchwork",
    "title": "In-Class_Ex04",
    "section": "Plot (patchwork)",
    "text": "Plot (patchwork)\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam_data,\n       aes(sample=ENGLISH)) +\n  stat_qq() + #normal distribution\n  stat_qq_line()\n\n\n\n\n\nset.seed(1234) #impt esp for variance statistics. to not change values everytime we run\n\n````{r} #"
  }
]